{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Probability of Successfully Passing the Group Phase <br> of the Football World Cup with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I am going to investigate the ways of predicting the outcome of the group phase of a Football World Cup \n",
    "based on the information known prior to the beginning of the World Cup. The Football World Cup is held every four years. \n",
    "Its group phase is structured such that in the beginning of the phase 32 national football teams from all over the world \n",
    "are split in 8 groups, each consisting of 4 teams. Only 2 teams from each group can pass the group and enter \n",
    "the next stage of the tournament, i.e. the “Round of 16”. Thus in total 16 teams out of 32 can successfully surmount the group phase. Therefore the tackled problem in this project represents a binary classification problem, i.e. for each team I am going to predict a label, which can take on only one of the two values, 1 (passed) or 0 (not passed) depending whether or not the team is predicted to pass the group phase.\n",
    "The data, which is known prior to the beginning of the respective Football World Cup, is basically the results of football matches played between this World Cup and the previous one, as well as the results of the qualifications for the respective World Cup for the national commands from different football confederations. There are currently six FIFA (Fédération Internationale de Football Association) confederations, depending on the geographical location (https://en.wikipedia.org/wiki/FIFA). Finding a unified feature set that would equally describe the chances of a team to pass the World Cup’s group phase (irregardless of which confederation it belongs to) is in my opinion one of the biggest challenges for this project, because each confederation has its own, i.e. different from other confederations, qualification format (https://en.wikipedia.org/wiki/FIFA_World_Cup_qualification). The main idea here would be to construct a feature set for a team, that is independent of the qualification format of a particular football confederation. An example of such feature might be e.g. an average number of goals scored by a team in the time span\n",
    "between two consecutive world cups. Then having such a feature set one could train a machine learning classifier and produce prediction for a desired team which is independent of qualification structure of a particular confederation. I am going to use a standard pipeline for the development of a machine learning model, which includes splitting the data into test/train subsets, perform hyperparameter optimization and training of the model on the train subset and test prediction capability on the test subset. Additionally, I have introduced a special weighting procedure in order to compute the aggregated features, which is based on a simple idea that the games that lie further in the past shall contribute lesser to the outcome of a particular World Cup.  Finally, since the posed problem is a symmetric binary classification problem, i.e. exactly the half of the teams can pass the group phase, I am going to use accuracy as the main metric. Throughout the project Python 3 is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Football Statistics Data Using Web-Scraping with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some modules first\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in labels\n",
    "df_labels = pd.read_csv('countries_and_labels.csv')\n",
    "# countries that took part in the world cups between 1998 and 2018\n",
    "countries_to_scrap = list(set(df_labels.country.tolist()))\n",
    "\n",
    "print(tabulate(df_labels.head(), headers='keys', tablefmt='fancy_grid',\n",
    "               floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in references\n",
    "f = open('data', 'r')\n",
    "refs = f.read()\n",
    "refs = refs.split('\\n')\n",
    "base_ref = refs[0]\n",
    "urls = refs[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def filter_out_non_fifa_countries(tag):\n",
    "    return tag.name == \"div\" and \"Non-FIFA\" not in tag.h4.string\n",
    "\n",
    "\n",
    "def construct_links_to_required_countries_and_years(url, hrefs):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    country_teams_tags = soup.body.section.find(\"div\", class_=\"row country-teams\")\n",
    "\n",
    "    fifa_and_former_countries = \\\n",
    "                        country_teams_tags.find_all(filter_out_non_fifa_countries)\n",
    "    \n",
    "    for div in fifa_and_former_countries:\n",
    "        countries = div.find_all(\"a\", href=re.compile('/country/'))\n",
    "\n",
    "        for country in countries:\n",
    "            cntr = str(country.string).strip()\n",
    "            if 'Serbia & Montenegro' in cntr:\n",
    "                cntr = 'Serbia & Montenegro'\n",
    "            \n",
    "            if cntr in countries_to_scrap:\n",
    "                dummy, c, n, team = country['href'].split('/')\n",
    "                \n",
    "                for year in range(1998,2019):\n",
    "                    href = '/' + c + '/' + n + '/' + str(year) + '/' + team\n",
    "                    hrefs.append((cntr, year, href))\n",
    "            \n",
    "    return hrefs\n",
    "\n",
    "\n",
    "hrefs = []\n",
    "for url in urls:\n",
    "    hrefs = construct_links_to_required_countries_and_years(url, hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define some filter functions\n",
    "\n",
    "def select_only_match_entries(cls):\n",
    "    return cls == 'win' or cls == 'draw' or cls == 'defeat' or cls == 'missing'\n",
    "\n",
    "\n",
    "def home_team_filter(cls):\n",
    "    return cls == \"teams home \" or cls == \"teams home winner\"\n",
    "\n",
    "\n",
    "def away_team_filter(cls):\n",
    "    return cls == \"teams away \" or cls == \"teams away winner\"\n",
    "\n",
    "\n",
    "# define some arrays for the data to be scrapped\n",
    "\n",
    "dates = []\n",
    "teams_home = []\n",
    "teams_away = []\n",
    "results_regular_time = []\n",
    "results_penalties = []\n",
    "game_types = []\n",
    "\n",
    "\n",
    "# scrap the matches data\n",
    "\n",
    "for href in hrefs:\n",
    "    url = base_ref+href[2]\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "        \n",
    "    matches_tags = soup.body.section.find('div', itemtype=re.compile('SportsTeam'))\\\n",
    "                       .find('div', class_=\"row country-details\").div.find('div', \\\n",
    "                                                              class_=\"tab-content\")\\\n",
    "                       .find('div', id=\"matches\").table.tbody \\\n",
    "                       .find_all(class_=select_only_match_entries)\n",
    "        \n",
    "    if len(matches_tags) != 0:\n",
    "        for tag in matches_tags:\n",
    "            # get match date\n",
    "            date = tag.find('td', class_=\"date\").string.strip()\n",
    "            dates.append(date)\n",
    "                \n",
    "            # get home team name\n",
    "            team_home = str(tag.find('td', class_=home_team_filter).a.span.string) \\\n",
    "                        .strip()\n",
    "            teams_home.append(team_home)\n",
    "                \n",
    "            # get away team name\n",
    "            team_away = str(tag.find('td', class_=away_team_filter).a.span.string) \\\n",
    "                        .strip()\n",
    "            teams_away.append(team_away)\n",
    "        \n",
    "            # get score in regular time\n",
    "            score = tag.find('td', class_=\"result\")\n",
    "            score_regular_time = score.a.find(\"span\", \\\n",
    "                                        title=re.compile('Result in regular time'))\n",
    "            if score_regular_time is not None:\n",
    "                score_regular_time = str(score_regular_time.string).strip()\n",
    "            else: \n",
    "                score_regular_time = str(score.a.string).strip()\n",
    "            results_regular_time.append(score_regular_time)\n",
    "                    \n",
    "            # get penalty shootout score\n",
    "            score_penalty_shootout = score.a.find(\"span\", \\\n",
    "                                              title=re.compile('Penalty shootout'))\n",
    "            if score_penalty_shootout is not None:\n",
    "                score_penalty_shootout = str(score_penalty_shootout.string).strip()\n",
    "            results_penalties.append(score_penalty_shootout)\n",
    "                    \n",
    "            # get game type\n",
    "            game_type = tag.find('td', class_=\"event\").a\n",
    "            if game_type is not None:\n",
    "                game_type = str(game_type.string).strip()\n",
    "            else:\n",
    "                game_type = str(tag.find('td', class_=\"event\").string).strip()\n",
    "            game_types.append(game_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation and Preprocessing with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe containing the data\n",
    "raw_data = pd.DataFrame({'date': dates, 'home_team': teams_home, \\\n",
    "                         'team_away': teams_away, 'score': results_regular_time, \\\n",
    "                         'penalties': results_penalties, 'game_type': game_types})\n",
    "\n",
    "raw_data = raw_data.drop_duplicates()\n",
    "\n",
    "raw_data['date'] = raw_data['date'].apply(lambda r: datetime.strptime(r, '%Y-%m-%d'))\n",
    "\n",
    "# print(tabulate(raw_data.head(), headers='keys', tablefmt='fancy_grid', \\\n",
    "# floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I define some auxiliary functions for the feature processing and aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goals_for(r):\n",
    "    \n",
    "    goals_for = 0\n",
    "    \n",
    "    if r.team[:-4] == r.home_team:\n",
    "        goals_for += int(r.score.split(':')[0])\n",
    "        if isinstance(r.penalties, str):\n",
    "            r.penalties\n",
    "            goals_for += int(r.penalties.split(':')[0])\n",
    "    else:\n",
    "        goals_for += int(r.score.split(':')[1])\n",
    "        if isinstance(r.penalties, str):\n",
    "            r.penalties\n",
    "            goals_for += int(r.penalties.split(':')[1])\n",
    "            \n",
    "    return goals_for\n",
    "\n",
    "\n",
    "def get_goals_against(r):\n",
    "    \n",
    "    goals_against = 0\n",
    "    \n",
    "    if r.team[:-4] == r.home_team:\n",
    "        goals_against += int(r.score.split(':')[1])\n",
    "        if isinstance(r.penalties, str):\n",
    "            r.penalties\n",
    "            goals_against += int(r.penalties.split(':')[1])\n",
    "    else:\n",
    "        goals_against += int(r.score.split(':')[0])\n",
    "        if isinstance(r.penalties, str):\n",
    "            r.penalties\n",
    "            goals_against += int(r.penalties.split(':')[0])\n",
    "            \n",
    "    return goals_against\n",
    "\n",
    "\n",
    "def get_features(df, raw_data_subset):\n",
    "\n",
    "    df['goals_for']     = raw_data_subset['goals_for'].mean()\n",
    "    df['goals_against'] = raw_data_subset['goals_against'].mean()\n",
    "    df['win_rate']      = raw_data_subset['win'].mean()\n",
    "    df['draw_rate']     = raw_data_subset['draw'].mean()\n",
    "    df['goals_diff']    = raw_data_subset['goals_diff'].mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def weighted_average(group, column_to_average):\n",
    "    \n",
    "    data = group[column_to_average]\n",
    "    weights = group['weight']\n",
    "    \n",
    "    return (data * weights).sum() / weights.sum()\n",
    "    \n",
    "\n",
    "def get_weighted_features(df, raw_data_subset):\n",
    "    \n",
    "    df['goals_for']     = weighted_average(raw_data_subset,'goals_for')\n",
    "    df['goals_against'] = weighted_average(raw_data_subset,'goals_against')\n",
    "    df['win_rate']      = weighted_average(raw_data_subset,'win')\n",
    "    df['draw_rate']     = weighted_average(raw_data_subset,'draw')\n",
    "    df['goals_diff']    = weighted_average(raw_data_subset,'goals_diff')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels[\"team\"] = df_labels.apply(lambda row: row.country + str(row.year), axis=1)\n",
    "teams_all_years = df_labels[\"team\"].tolist()\n",
    "\n",
    "df_labels = df_labels.drop(['country', 'year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame for the final aggregated features\n",
    "cols = ['team']\n",
    "aggregated_data = pd.DataFrame(columns=cols)\n",
    "\n",
    "# set to True in order to use only the matches' data one year \n",
    "# before the respective world cup\n",
    "last_year = True \n",
    "# if flag weight_average True, the weighted averages of features are computed \n",
    "# such that the matches that further in the pass influence the average lesser\n",
    "weight_average = True \n",
    "\n",
    "# loop over all 160 teams and calculate features for them\n",
    "for team in teams_all_years:\n",
    "    year = team[-4:]\n",
    "    \n",
    "    # set the interval over which to average the matches' data for a \n",
    "    # paticular team and year\n",
    "    time_from = None\n",
    "    time_to = None\n",
    "    if year == '2018':\n",
    "        time_to = datetime.strptime('2018-06-13', '%Y-%m-%d')\n",
    "        if last_year:\n",
    "            time_from = time_to - relativedelta(years=1)\n",
    "        else:\n",
    "            time_from = datetime.strptime('2014-07-14', '%Y-%m-%d')\n",
    "    elif year == '2014':\n",
    "        time_to   = datetime.strptime('2014-06-11', '%Y-%m-%d')\n",
    "        if last_year:\n",
    "            time_from = time_to - relativedelta(years=1)\n",
    "        else:\n",
    "            time_from = datetime.strptime('2010-07-12', '%Y-%m-%d')\n",
    "    elif year == '2010':\n",
    "        time_to   = datetime.strptime('2010-06-11', '%Y-%m-%d')\n",
    "        if last_year:\n",
    "            time_from = time_to - relativedelta(years=1)\n",
    "        else:\n",
    "            time_from = datetime.strptime('2006-07-10', '%Y-%m-%d')\n",
    "    elif year == '2006':\n",
    "        time_to   = datetime.strptime('2006-06-09', '%Y-%m-%d')\n",
    "        if last_year:\n",
    "            time_from = time_to - relativedelta(years=1)\n",
    "        else:\n",
    "            time_from = datetime.strptime('2002-07-01', '%Y-%m-%d')\n",
    "    elif year == '2002':\n",
    "        time_to   = datetime.strptime('2002-07-01', '%Y-%m-%d')\n",
    "        if last_year:\n",
    "            time_from = time_to - relativedelta(years=1)\n",
    "        else:\n",
    "            time_from = datetime.strptime('1998-07-14', '%Y-%m-%d')\n",
    "       \n",
    "    # create a data frame for the features for the current team and year\n",
    "    df = pd.DataFrame([team], columns=cols)\n",
    "    \n",
    "    # take only matches data for the current team\n",
    "    raw_data_subset = raw_data[(raw_data.home_team == team[:-4]) | \\\n",
    "                               (raw_data.team_away == team[:-4])]\n",
    "    \n",
    "    # take only the matches that took place before the specific World Cup \n",
    "    # in the year 'year' but after the previous World Cup \n",
    "    raw_data_subset = raw_data_subset[(raw_data_subset.date > time_from) & \\\n",
    "                                      (raw_data_subset.date < time_to)]\n",
    "    \n",
    "    # filter out games without score\n",
    "    raw_data_subset = raw_data_subset[~(raw_data_subset.score == '-:-')]\n",
    "    \n",
    "    # transform raw features in order to obtain some intermediate features\n",
    "    raw_data_subset['team'] = team\n",
    "    \n",
    "    raw_data_subset['goals_for'] = raw_data_subset.apply(get_goals_for, axis=1)\n",
    "    \n",
    "    raw_data_subset['goals_against'] = raw_data_subset.apply(get_goals_against, \\\n",
    "                                                             axis=1)\n",
    "    \n",
    "    raw_data_subset['goals_diff'] = raw_data_subset \\\n",
    "                         .apply(lambda r: r.goals_for - r.goals_against, axis=1)\n",
    "    \n",
    "    raw_data_subset['win'] = raw_data_subset \\\n",
    "                           .apply(lambda r: 1 if r.goals_diff > 0 else 0, axis=1)\n",
    "    \n",
    "    raw_data_subset['draw'] = raw_data_subset \\\n",
    "                           .apply(lambda r: 1 if r.goals_diff == 0 else 0, axis=1)\n",
    "    \n",
    "    raw_data_subset['weight'] = raw_data_subset \\\n",
    "                        .apply(lambda r: 1./ int((time_to - r.date).days), axis=1)\n",
    "    \n",
    "    # type conversion for the purpose of calcution of mean values later on\n",
    "    raw_data_subset['goals_for'] = raw_data_subset['goals_for'].astype('float')\n",
    "    raw_data_subset['goals_against'] = raw_data_subset['goals_against'] \\\n",
    "                                       .astype('float')\n",
    "    raw_data_subset['goals_diff'] = raw_data_subset['goals_diff'].astype('float')\n",
    "    raw_data_subset['win'] = raw_data_subset['win'].astype('float')\n",
    "    raw_data_subset['draw'] = raw_data_subset['draw'].astype('float')\n",
    "    \n",
    "    # aggregate the previously filtered data in order to calculate final features\n",
    "    if weight_average:\n",
    "        df = get_weighted_features(df, raw_data_subset)\n",
    "    else:\n",
    "        df = get_features(df, raw_data_subset)\n",
    "    \n",
    "    aggregated_data = aggregated_data.append(df, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tabulate(aggregated_data.head()[['team', 'win_rate', 'goals_for', 'goals_against', \n",
    "#'goals_diff', 'draw_rate']], headers='keys', tablefmt='fancy_grid', floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge labels and features into a single dataframe\n",
    "aggregated_data_labels = pd.merge(aggregated_data, df_labels, on='team', \\\n",
    "                                  how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Probability of Passing the Group Phase of the Football World Cup using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naively thinking, one could assume that the probably out of all the above features the two, namely win_rate and goals_for, would be directly proportional to the probability of passing the group phase. But in the reality the situation is more complicated. In order to demonstrate this point the cell below can be executed in order to plot the seperation boundary for these two features as obtained from the SVM model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSize = 0.2\n",
    "\n",
    "def plot_boundaries(aggregated_data, features):\n",
    "\n",
    "    # fit a very simple SVM model in order to obtain seperation boundaries\n",
    "    data = aggregated_data[features].values\n",
    "    labels = aggregated_data['passed_group_phase'].values\n",
    "\n",
    "    # split the aggregated teams data into test and train subsets\n",
    "    data_train, data_test, labels_train, labels_test = train_test_split(data, \\\n",
    "                                    labels, test_size=TestSize, random_state=0)\n",
    "    \n",
    "    # apply feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    data_train = scaler.fit_transform(data_train)\n",
    "    data_test  = scaler.transform(data_test)\n",
    "    \n",
    "    # create classifier\n",
    "    classifier = SVC(kernel='linear',random_state=0, gamma=0.02)\n",
    "    classifier.fit(data_train, labels_train)\n",
    "    \n",
    "    # plot boundaries\n",
    "    x_min = data_train[:,0].min()\n",
    "    x_max = data_train[:,0].max()\n",
    "    \n",
    "    y_min = data_train[:,1].min()\n",
    "    y_max = data_train[:,1].max()\n",
    "    \n",
    "    w = classifier.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "\n",
    "    xx = np.linspace(x_min, x_max)\n",
    "    yy = a * xx - (classifier.intercept_[0]) / w[1]\n",
    "    yy_min = yy.min()\n",
    "    yy_max = yy.max()\n",
    "    if yy_min < y_min:\n",
    "        y_min = yy_min\n",
    "    if yy_max > y_max:\n",
    "        y_max = yy_max\n",
    "\n",
    "    margin = 1 / np.sqrt(np.sum(classifier.coef_ ** 2))\n",
    "    yy_down = yy - np.sqrt(1 + a ** 2) * margin\n",
    "    if yy_down.min() < y_min:\n",
    "        y_min = yy_down.min()\n",
    " \n",
    "    yy_up = yy + np.sqrt(1 + a ** 2) * margin\n",
    "    if yy_up.max() > y_max:\n",
    "        y_max = yy_up.max()\n",
    "\n",
    "    plt.figure(1, figsize=(4, 3))\n",
    "    plt.clf()\n",
    "    plt.plot(xx, yy, 'k-')\n",
    "    plt.plot(xx, yy_down, 'k--')\n",
    "    plt.plot(xx, yy_up, 'k--')\n",
    "\n",
    "    plt.scatter(classifier.support_vectors_[:, 0], \\\n",
    "                classifier.support_vectors_[:, 1], s=80, facecolors='none', \\\n",
    "                zorder=10, edgecolors='k')\n",
    "    plt.scatter(data_train[:,0], data_train[:,1], c=labels_train, zorder=10, \\\n",
    "                cmap=plt.cm.Paired, edgecolors='k')\n",
    "    \n",
    "    plt.axis('tight')\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = classifier.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.figure(1, figsize=(4, 3))\n",
    "    plt.pcolormesh(XX, YY, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    plt.xlabel(\"goals_for\")\n",
    "    plt.ylabel(\"win_rate\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # make predicion on the test set\n",
    "    #labels_pred  = classifier.predict(data_test)\n",
    "    #print(\"Accuracy: {}\".format(accuracy_score(labels_test, labels_pred)))\n",
    "\n",
    "plot_boundaries(aggregated_data_labels, ['goals_for', 'win_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some auxiliary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(aggregated_data, features, clsfr):\n",
    "    \n",
    "    data = aggregated_data[features].values\n",
    "    labels = aggregated_data['passed_group_phase'].values\n",
    "    \n",
    "    # split the aggregated teams data into test and train subsets\n",
    "    data_train, data_test, labels_train, labels_test = train_test_split(data, \\\n",
    "                                    labels, test_size=TestSize, random_state=0)\n",
    "    \n",
    "    # apply feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    data_train = scaler.fit_transform(data_train)\n",
    "    data_test  = scaler.transform(data_test)\n",
    "    \n",
    "    # create classifier\n",
    "    classifier = clsfr\n",
    "\n",
    "    classifier.fit(data_train, labels_train)\n",
    "\n",
    "    # make predicion on the test set\n",
    "    labels_pred  = classifier.predict(data_test)\n",
    "\n",
    "    # evaluate the accuracy metric\n",
    "    return accuracy_score(labels_test, labels_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below carries out a simple feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some variables for the future use\n",
    "features = ['goals_for', 'goals_against', 'win_rate', 'draw_rate']\n",
    "features_opt_reg = []\n",
    "features_opt_svc = []\n",
    "score_reg_prev = 0\n",
    "score_svc_prev = 0\n",
    "    \n",
    "# build all possible combinations of features\n",
    "feature_combinations = []\n",
    "for L in range(0, len(features)+1):\n",
    "    for subset in itertools.combinations(features, L):\n",
    "        if list(subset):\n",
    "            feature_combinations.append(list(subset))\n",
    "\n",
    "#define classifiers\n",
    "classifier_logit = LogisticRegression(random_state=0)\n",
    "classifier_svc = SVC(kernel='rbf',random_state=0)\n",
    "\n",
    "# calculate the accuracy score for each combination of features \n",
    "# and chose the feature combination with the best score\n",
    "for feature_combination in feature_combinations:\n",
    "        \n",
    "    print (\"--------------------------------------------------------------\")\n",
    "    print (\"FEATURES: {}\".format(feature_combination))\n",
    "        \n",
    "    # fit logistic regression\n",
    "    score_reg  = classification(aggregated_data_labels, feature_combination, \\\n",
    "                                classifier_logit)\n",
    "    print (\"{0:26s} {1:10.8f}\".format('LOGISTIC REGRESSION SCORE:', score_reg))\n",
    "        \n",
    "    # fit SVC\n",
    "    score_svc  = classification(aggregated_data_labels, feature_combination, \\\n",
    "                                classifier_svc)\n",
    "    print (\"{0:26s} {1:10.8f}\".format('SVC SCORE:', score_svc))\n",
    "        \n",
    "    # update the optimal feature combination for the logistic regression model\n",
    "    # if the new score is higher than the one for the previous feature combination \n",
    "    if score_reg >= score_reg_prev:\n",
    "        features_opt_reg = feature_combination\n",
    "        score_reg_prev = score_reg\n",
    "            \n",
    "    # update the optimal feature combination for the SCV model\n",
    "    # if the new score is higher than the one for the previous feature combination \n",
    "    if score_svc >= score_svc_prev:\n",
    "        features_opt_svc = feature_combination\n",
    "        score_svc_prev = score_svc\n",
    "    \n",
    "# print final results\n",
    "print (\"\\n\")\n",
    "print (\"Optimal features for logistic regression: {}\\n Score: {}\". \\\n",
    "       format(features_opt_reg, score_reg_prev))\n",
    "print (\"Optimal features for SVM: {}\\n Score: {}\". \\\n",
    "       format(features_opt_svc, score_svc_prev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the cell above one would be able to see that for the current problem the classification based on the logistic regression outperforms the support vector machine classification. <br>\n",
    "Further, the usage of the weighted average described above allows to achieve the accuracy score that is larger than 81%! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define auxiliary function to perform the fine tuning of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(classifier, parameters, aggregated_data, features):\n",
    "    \n",
    "    data = aggregated_data[features].values\n",
    "    labels = aggregated_data['passed_group_phase'].values\n",
    "    \n",
    "    # split the aggregated teams data into test and train subsets\n",
    "    data_train, data_test, labels_train, labels_test = train_test_split(data, \\\n",
    "                                    labels, test_size=TestSize, random_state=0)\n",
    "    \n",
    "    # apply feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    data_train = scaler.fit_transform(data_train)\n",
    "    data_test  = scaler.transform(data_test)\n",
    "    \n",
    "    # Create an instance of the GridSearchCV class\n",
    "    clf = GridSearchCV(classifier, parameters, scoring=make_scorer(accuracy_score),\\\n",
    "                       cv=5, n_jobs=-1)\n",
    "    \n",
    "    # perform the grid search on the train data\n",
    "    clf.fit(data_train, labels_train)\n",
    "    \n",
    "    # predict based on the best fitted model labels for the test dataset\n",
    "    labels_pred  = clf.predict(data_test)\n",
    "    \n",
    "    return clf.best_params_, accuracy_score(labels_test, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By carrying out the next cell one can perform the grid-search on the optimized feature set for the logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "parameters = {'C': list(np.linspace(0.1,10,100)), \\\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "best_params_reg, score = grid_search(classifier, parameters, \\\n",
    "                                     aggregated_data_labels, features_opt_reg)\n",
    "print (\"Score: {}\".format(score))\n",
    "print (\"Best parameters: {}\".format(best_params_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By carrying out the next cell one can perform the grid-search on the optimized feature set for the SVM classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "classifier = SVC(kernel='rbf',random_state=0)\n",
    "parameters = {'gamma': list(np.linspace(0.1,1,19)), \\\n",
    "              'C': list(np.linspace(0.5,1,50)), 'degree': [1,2,3,4,5,6,7,8,9,10] }\n",
    "best_params_svm, score = grid_search(classifier, parameters, \\\n",
    "                                     aggregated_data_labels, features_opt_svc)\n",
    "print (\"Score: {}\".format(score))\n",
    "print (\"Best parameters: {}\".format(best_params_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
